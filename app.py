import os\nimport time\nimport json\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import Dict, Any, Tuple\nfrom flask import Flask, jsonify, request, g\nfrom flask_cors import CORS\nimport psycopg2\nfrom psycopg2.extras import RealDictCursor\nfrom psycopg2.pool import ThreadedConnectionPool\nimport signal\nimport sys\nfrom functools import wraps\n\n# Production logging configuration\nclass JSONFormatter(logging.Formatter):\n    def format(self, record):\n        log_entry = {\n            'timestamp': datetime.now(timezone.utc).isoformat(),\n            'level': record.levelname,\n            'message': record.getMessage(),\n            'module': record.module,\n            'function': record.funcName,\n            'line': record.lineno,\n            'process_id': os.getpid()\n        }\n        if record.exc_info:\n            log_entry['exception'] = self.formatException(record.exc_info)\n        return json.dumps(log_entry)\n\ndef setup_logging():\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n    logger.handlers.clear()\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(JSONFormatter())\n    logger.addHandler(handler)\n    return logging.getLogger(__name__)\n\nlogger = setup_logging()\n\nclass Config:\n    def __init__(self):\n        self.DATABASE_URL = os.environ.get('DATABASE_URL')\n        self.ENVIRONMENT = os.environ.get('ENVIRONMENT', 'development')\n        self.VERSION = os.environ.get('APP_VERSION', '1.0.0')\n        self.PORT = int(os.environ.get('PORT', 5000))\n        self.DEBUG = self.ENVIRONMENT == 'development'\n        self.SECRET_KEY = os.environ.get('SECRET_KEY', 'dev-key-change-in-production')\n        self.DB_MIN_CONNECTIONS = int(os.environ.get('DB_MIN_CONNECTIONS', '2'))\n        self.DB_MAX_CONNECTIONS = int(os.environ.get('DB_MAX_CONNECTIONS', '10'))\n        self._validate_config()\n    \n    def _validate_config(self):\n        if not self.DATABASE_URL and self.ENVIRONMENT == 'production':\n            raise ValueError("DATABASE_URL is required in production")\n        if self.SECRET_KEY == 'dev-key-change-in-production' and self.ENVIRONMENT == 'production':\n            logger.warning("Using default secret key in production!")\n\nconfig = Config()\ndb_pool = None\n\ndef init_db_pool():\n    global db_pool\n    if not config.DATABASE_URL:\n        logger.warning("No DATABASE_URL provided, running without database")\n        return\n    try:\n        db_pool = ThreadedConnectionPool(\n            config.DB_MIN_CONNECTIONS,\n            config.DB_MAX_CONNECTIONS,\n            config.DATABASE_URL,\n            cursor_factory=RealDictCursor\n        )\n        logger.info(f"Database pool initialized with {config.DB_MIN_CONNECTIONS}-{config.DB_MAX_CONNECTIONS} connections")\n        with get_db_connection() as conn:\n            with conn.cursor() as cursor:\n                cursor.execute(\"\"\"\n                    CREATE TABLE IF NOT EXISTS users (\n                        id SERIAL PRIMARY KEY,\n                        name VARCHAR(100) NOT NULL,\n                        email VARCHAR(255) UNIQUE NOT NULL,\n                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n                        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n                    );\n                    CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);\n                    CREATE INDEX IF NOT EXISTS idx_users_created_at ON users(created_at);\n                \"\"\")\n                conn.commit()\n                logger.info("Database schema initialized successfully")\n    except Exception as e:\n        logger.error(f"Failed to initialize database pool: {e}")\n        raise\n\ndef get_db_connection():\n    if not db_pool:\n        raise RuntimeError("Database pool not initialized")\n    return db_pool.getconn()\n\ndef return_db_connection(conn):\n    if db_pool and conn:\n        db_pool.putconn(conn)\n\ndef request_metrics(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        start_time = time.time()\n        try:\n            response = f(*args, **kwargs)\n            status_code = response[1] if isinstance(response, tuple) else 200\n        except Exception as e:\n            logger.error(f"Request failed: {e}")\n            status_code = 500\n            raise\n        finally:\n            response_time = int((time.time() - start_time) * 1000)\n            logger.info(f"Request completed", extra={\n                'endpoint': request.endpoint,\n                'method': request.method,\n                'status_code': status_code,\n                'response_time_ms': response_time,\n                'user_agent': request.headers.get('User-Agent'),\n                'ip_address': request.remote_addr\n            })\n        return response\n    return decorated_function\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = config.SECRET_KEY\nCORS(app)\n\n@app.route('/health')\n@request_metrics\ndef health_check():\n    health_status = {\n        "status": "healthy",\n        "timestamp": datetime.now(timezone.utc).isoformat(),\n        "version": config.VERSION,\n        "environment": config.ENVIRONMENT,\n        "checks": {}\n    }\n    \n    if db_pool:\n        try:\n            conn = get_db_connection()\n            with conn.cursor() as cursor:\n                cursor.execute("SELECT 1")\n                cursor.fetchone()\n            return_db_connection(conn)\n            health_status["checks"]["database"] = "healthy"\n        except Exception as e:\n            health_status["checks"]["database"] = f"unhealthy: {str(e)}"\n            health_status["status"] = "unhealthy"\n    else:\n        health_status["checks"]["database"] = "not configured"\n    \n    try:\n        import psutil\n        memory_percent = psutil.virtual_memory().percent\n        health_status["checks"]["memory"] = {\n            "usage_percent": round(memory_percent, 2),\n            "status": "healthy" if memory_percent < 90 else "warning"\n        }\n        if memory_percent > 95:\n            health_status["status"] = "unhealthy"\n    except ImportError:\n        health_status["checks"]["memory"] = "monitoring not available"\n    \n    status_code = 200 if health_status["status"] == "healthy" else 503\n    return jsonify(health_status), status_code\n\n@app.route('/ready')\n@request_metrics\ndef readiness_check():\n    if db_pool:\n        try:\n            conn = get_db_connection()\n            with conn.cursor() as cursor:\n                cursor.execute("SELECT 1")\n            return_db_connection(conn)\n            return jsonify({"status": "ready"}), 200\n        except Exception as e:\n            logger.error(f"Readiness check failed: {e}")\n            return jsonify({"status": "not ready", "reason": str(e)}), 503\n    return jsonify({"status": "ready"}), 200\n\n@app.route('/metrics')\n@request_metrics\ndef metrics():\n    try:\n        metrics_data = {\n            "app_info": {\n                "version": config.VERSION,\n                "environment": config.ENVIRONMENT,\n                "uptime_seconds": int(time.time())\n            }\n        }\n        \n        if db_pool:\n            conn = get_db_connection()\n            with conn.cursor() as cursor:\n                cursor.execute("SELECT COUNT(*) as count FROM users")\n                user_count = cursor.fetchone()['count']\n                metrics_data["database_users_total"] = user_count\n            return_db_connection(conn)\n        \n        try:\n            import psutil\n            metrics_data.update({\n                "system_memory_usage_percent": psutil.virtual_memory().percent,\n                "system_cpu_usage_percent": psutil.cpu_percent()\n            })\n        except ImportError:\n            pass\n        \n        return jsonify(metrics_data), 200\n        \n    except Exception as e:\n        logger.error(f"Error generating metrics: {e}")\n        return jsonify({"error": "metrics unavailable"}), 500\n\n@app.route('/')\n@request_metrics\ndef root():\n    return jsonify({\n        "service": "DevOps Production Demo API",\n        "version": config.VERSION,\n        "environment": config.ENVIRONMENT,\n        "timestamp": datetime.now(timezone.utc).isoformat(),\n        "endpoints": {\n            "health": "/health",\n            "readiness": "/ready",\n            "metrics": "/metrics",\n            "users": "/users"\n        }\n    })\n\n@app.route('/users', methods=['GET', 'POST'])\n@request_metrics\ndef users():\n    if not db_pool:\n        return jsonify({"error": "Database not available"}), 503\n    \n    if request.method == 'GET':\n        try:\n            page = int(request.args.get('page', 1))\n            limit = min(int(request.args.get('limit', 10)), 100)\n            offset = (page - 1) * limit\n            \n            conn = get_db_connection()\n            with conn.cursor() as cursor:\n                cursor.execute("SELECT COUNT(*) as count FROM users")\n                total_count = cursor.fetchone()['count']\n                cursor.execute(\"\"\"\n                    SELECT id, name, email, created_at \n                    FROM users \n                    ORDER BY created_at DESC \n                    LIMIT %s OFFSET %s\n                \"\"\", (limit, offset))\n                users_data = cursor.fetchall()\n            \n            return_db_connection(conn)\n            \n            return jsonify({\n                "users": [dict(user) for user in users_data],\n                "pagination": {\n                    "page": page,\n                    "limit": limit,\n                    "total": total_count,\n                    "pages": (total_count + limit - 1) // limit\n                }\n            }), 200\n            \n        except ValueError:\n            return jsonify({"error": "Invalid pagination parameters"}), 400\n        except Exception as e:\n            logger.error(f"Error fetching users: {e}")\n            return jsonify({"error": "Internal server error"}), 500\n    \n    elif request.method == 'POST':\n        try:\n            data = request.get_json()\n            if not data:\n                return jsonify({"error": "JSON body required"}), 400\n            \n            required_fields = ['name', 'email']\n            missing_fields = [field for field in required_fields if not data.get(field)]\n            if missing_fields:\n                return jsonify({\n                    "error": "Missing required fields",\n                    "missing": missing_fields\n                }), 400\n            \n            email = data['email'].strip().lower()\n            if '@' not in email or '.' not in email:\n                return jsonify({"error": "Invalid email format"}), 400\n            \n            conn = get_db_connection()\n            with conn.cursor() as cursor:\n                cursor.execute(\"\"\"\n                    INSERT INTO users (name, email, created_at) \n                    VALUES (%s, %s, %s) \n                    RETURNING id, name, email, created_at\n                \"\"\", (data['name'].strip(), email, datetime.now(timezone.utc)))\n                \n                new_user = cursor.fetchone()\n                conn.commit()\n            \n            return_db_connection(conn)\n            \n            logger.info(f"Created user {new_user['id']}: {new_user['name']}")\n            return jsonify({\n                "message": "User created successfully",\n                "user": dict(new_user)\n            }), 201\n            \n        except psycopg2.IntegrityError:\n            return jsonify({"error": "Email already exists"}), 409\n        except Exception as e:\n            logger.error(f"Error creating user: {e}")\n            return jsonify({"error": "Internal server error"}), 500\n\n@app.errorhandler(404)\ndef not_found(error):\n    return jsonify({"error": "Endpoint not found"}), 404\n\n@app.errorhandler(405)\ndef method_not_allowed(error):\n    return jsonify({"error": "Method not allowed"}), 405\n\n@app.errorhandler(500)\ndef internal_error(error):\n    logger.error(f"Internal server error: {error}")\n    return jsonify({"error": "Internal server error"}), 500\n\ndef signal_handler(sig, frame):\n    logger.info("Received shutdown signal, cleaning up...")\n    if db_pool:\n        db_pool.closeall()\n        logger.info("Database connections closed")\n    sys.exit(0)\n\nsignal.signal(signal.SIGINT, signal_handler)\nsignal.signal(signal.SIGTERM, signal_handler)\n\nif __name__ == '__main__':\n    logger.info(f"Starting application version {config.VERSION} in {config.ENVIRONMENT} mode")\n    if config.DATABASE_URL:\n        init_db_pool()\n    logger.info(f"Starting server on port {config.PORT}")\n    app.run(\n        host='0.0.0.0',\n        port=config.PORT,\n        debug=config.DEBUG,\n        threaded=True\n    )\n